{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "- Create a directory `data/medical/data` with subdirectories `data/medical/data/raw` and `data/medical/processed`\n",
    "- Extract the static data fields using the python script in the cell below. NOTE: this assumes that you have an `enc_ukb` file from UK Biobank and the software programs for working with this type of file. You will need to update `data_command` in the script below to provide the correct filepaths for your `enc_ukb` file and software\n",
    "- The rest of the code assumes you have the UK Biobank Primary Care Linked Data stored in an SQLite database called `ehr.db` for the tables `gp_clinical` and `gp_scripts`. See [UK Biobank Resource 591](https://biobank.ndph.ox.ac.uk/showcase/refer.cgi?id=591) for further details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a file with the fields for extraction\n",
    "df = pd.read_csv('inputs/covariates.txt')\n",
    "fields = df[df['Type']=='static']['Code'].tolist()\n",
    "with open('data/fields.txt', 'w') as f:\n",
    "    for field in fields:\n",
    "        f.write(\"%s\\n\" % field)\n",
    "\n",
    "data_command = 'ukbconv ukbxxxx.enc_ukb csv -ifields.txt -oukbxxxx' # TODO update this command with your filepaths\n",
    "os.system(data_command) # alternatively, copy the command into your bash shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify filepaths and database location\n",
    "# TODO update these for your filepaths\n",
    "\n",
    "OUTPATH = 'data/raw'\n",
    "DATAPATH = 'data/ukbxxxxcsv'\n",
    "\n",
    "df = pd.read_csv(DATAPATH)\n",
    "fields_df = pd.read_csv('inputs/covariates.txt')\n",
    "covariate_fields_df = fields_df[fields_df['Variable']=='covariate']\n",
    "clinical_fields_df = fields_df[fields_df['Variable']=='clinical']\n",
    "diagnosis_fields_df = fields_df[fields_df['Variable']=='diagnosis']\n",
    "resp_df = pd.read_csv('inputs/response.txt')\n",
    "tre_df = pd.read_csv('inputs/treatment.txt')\n",
    "\n",
    "# connection to db\n",
    "DBPATH = 'data/ehr/ehr.db'\n",
    "conn = sqlite3.connect(DBPATH)\n",
    "conn.text_factory = lambda b: b.decode(errors = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function for removing outliers from a column in a pandas dataframe\n",
    "outlier_df = lambda df, col: df[(np.abs(stats.zscore(df[col])) < 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess patient list and static covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## format static data (diagnosis covariates and other covariates)\n",
    "df = pd.read_csv(DATAPATH)\n",
    "diagnosis_var = '130708-0.0'\n",
    "data = df[['eid',diagnosis_var]].rename(columns={diagnosis_var:'T2D_diagnosis_date'}).dropna()\n",
    "field_list = dict(zip(covariate_fields_df['Code'], covariate_fields_df['Description']))\n",
    "\n",
    "if '31' in field_list:\n",
    "    # sex\n",
    "    tmp = df[['eid', '31-0.0']].rename(columns={'31-0.0':field_list['31']})\n",
    "    data = pd.merge(data, tmp, on='eid')\n",
    "\n",
    "if '34' in field_list:\n",
    "    # year of birth\n",
    "    tmp = df[['eid', '34-0.0']].rename(columns={'34-0.0':field_list['34']})\n",
    "    data = pd.merge(data, tmp, on='eid')\n",
    "\n",
    "## patient cohort: get patients with T2D diagnosis\n",
    "patient_list = df['eid'].tolist()\n",
    "data.to_csv('{}/patient_covariates.csv'.format(OUTPATH), index=None)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table='gp_clinical'\n",
    "read2_codes = ', '.join([\"'{}'\".format(x) for x in resp_df[resp_df['Type']=='read2']['Code']])\n",
    "read3_codes = ', '.join([\"'{}'\".format(x) for x in resp_df[resp_df['Type']=='read3']['Code']])\n",
    "\n",
    "if len(read2_codes)>0 and len(read3_codes)>0:\n",
    "    command = 'SELECT * FROM {} WHERE (read_2 IN ({}) OR read_3 IN ({}))'.format(table, read2_codes, read3_codes)\n",
    "elif len(read2_codes)>0:\n",
    "    command = 'SELECT * FROM {} WHERE read_2 IN ({})'.format(table, read2_codes)\n",
    "elif len(read3_codes)>0:\n",
    "    command = 'SELECT * FROM {} WHERE read_3 IN ({})'.format(table, read3_codes)\n",
    "\n",
    "data = pd.read_sql_query(command, conn)\n",
    "\n",
    "# data cleaning\n",
    "data['y'] = pd.to_numeric(data['value1'], errors='coerce')\n",
    "data = data[['eid','event_dt','y']]\n",
    "data = data[data['eid'].astype('int').isin(patient_list)]\n",
    "data = data.dropna()\n",
    "data = data[~(data['event_dt']=='')]\n",
    "data['event_dt'] = pd.to_datetime(data['event_dt'], format='%d/%m/%Y')\n",
    "data = outlier_df(data, 'y')\n",
    "\n",
    "data = data[data['y']>0]\n",
    "data.to_csv('{}/response.csv'.format(OUTPATH), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess treatment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table='gp_scripts'\n",
    "\n",
    "read2_codes = ', '.join([\"'{}'\".format(x) for x in tre_df[tre_df['Type']=='read_2']['Code']])\n",
    "bnf_codes = ', '.join([\"'{}'\".format(x) for x in tre_df[tre_df['Type']=='bnf_code']['Code']])\n",
    "dmd_codes = ', '.join([\"'{}'\".format(x) for x in tre_df[tre_df['Type']=='dmd_code']['Code']])\n",
    "\n",
    "command = 'SELECT * FROM {} WHERE (read_2 IN ({}) OR bnf_code IN ({}) OR dmd_code IN ({}))'.format(table, read2_codes, bnf_codes, dmd_codes)\n",
    "\n",
    "data = pd.read_sql_query(command, conn)\n",
    "\n",
    "# map the codes to the drug label\n",
    "code_map = dict(zip(tre_df['Code'],tre_df['Label'])) # use read 2 codes because drug name is blank\n",
    "t1 = data[data['read_2']!='']\n",
    "t1['treatment'] = t1['read_2'].map(code_map)\n",
    "t2 = data[data['read_2']=='']\n",
    "code_map = dict(zip(tre_df['Description'],tre_df['Label'])) # use description because other drugs had same codes\n",
    "t2['treatment'] = t2['drug_name'].map(code_map)\n",
    "\n",
    "data = pd.concat([t1,t2])\n",
    "\n",
    "# try to match remaining names\n",
    "\n",
    "treatments = {'atorvastatin':'atorvastatin',\n",
    "              'lipitor':'atorvastatin', \n",
    "              'fluvastatin':'fluvastatin', \n",
    "              'lescol':'fluvastatin', \n",
    "              'lovastatin':'lovastatin',\n",
    "              'altoprev':'lovastatin', \n",
    "              'pitavastatin':'pitavastatin', \n",
    "              'livalo':'pitavastatin', \n",
    "              'zypitamag':'pitavastatin', \n",
    "              'pravastatin':'pravastatin',\n",
    "              'pravachol':'pravastatin', \n",
    "              'rosuvastatin':'rosuvastatin',\n",
    "              'crestor':'rosuvastatin',\n",
    "              'ezallor':'rosuvastatin', \n",
    "              'simvastatin':'simvastatin', \n",
    "              'zocor':'simvastatin'}\n",
    "\n",
    "t1 = data[~data['treatment'].isna()]\n",
    "t2 = data[data['treatment'].isna()]\n",
    "\n",
    "t2['treatment'] = t2['drug_name'].apply(lambda x: next((v for k, v in treatments.items() if k in x.lower()), None))\n",
    "\n",
    "# remove any drugs that seem to be billed across wrong codes (could also check manually)\n",
    "t2 = t2[~t2['treatment'].isna()]\n",
    "data = pd.concat([t1,t2])\n",
    "\n",
    "# data cleaning\n",
    "data = data[['eid','issue_date','treatment']]\n",
    "data = data[data['eid'].astype('int').isin(patient_list)]\n",
    "data = data.dropna()\n",
    "data = data[~(data['issue_date']=='')]\n",
    "data['issue_date'] = pd.to_datetime(data['issue_date'], format='%d/%m/%Y')\n",
    "data.rename(columns={'issue_date':'event_dt'}, inplace=True)\n",
    "\n",
    "data.to_csv('{}/treatment.csv'.format(OUTPATH), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess clinical covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table='gp_clinical'\n",
    "read2_codes = ', '.join([\"'{}'\".format(x) for x in clinical_fields_df[clinical_fields_df['Type']=='read2']['Code']])\n",
    "read3_codes = ', '.join([\"'{}'\".format(x) for x in clinical_fields_df[clinical_fields_df['Type']=='read3']['Code']])\n",
    "\n",
    "if len(read2_codes)>0 and len(read3_codes)>0:\n",
    "    command = 'SELECT * FROM {} WHERE (read_2 IN ({}) OR read_3 IN ({}))'.format(table, read2_codes, read3_codes)\n",
    "elif len(read2_codes)>0:\n",
    "    command = 'SELECT * FROM {} WHERE read_2 IN ({})'.format(table, read2_codes)\n",
    "elif len(read3_codes)>0:\n",
    "    command = 'SELECT * FROM {} WHERE read_3 IN ({})'.format(table, read3_codes)\n",
    "    \n",
    "data = pd.read_sql_query(command, conn)\n",
    "\n",
    "# data cleaning\n",
    "code_map = dict(zip(clinical_fields_df['Code'],clinical_fields_df['Description']))\n",
    "data['read_3'] = data['read_3'].map(code_map)\n",
    "data['read_2'] = data['read_2'].map(code_map)\n",
    "data['read_3'] = data['read_3'].fillna(data['read_2'])\n",
    "data['value'] = pd.to_numeric(data['value1'], errors='coerce')\n",
    "data = data[['eid','event_dt','read_3','value']]\n",
    "data = data[data['eid'].astype('int').isin(patient_list)]\n",
    "data = data.dropna()\n",
    "data = data[~(data['event_dt']=='')]\n",
    "data['event_dt'] = pd.to_datetime(data['event_dt'], format='%d/%m/%Y')\n",
    "data.rename(columns={'read_3':'variable'}, inplace=True)\n",
    "\n",
    "# data should not be zero-valued\n",
    "data = data[data['value']>0] \n",
    "\n",
    "# remove outliers for each variable\n",
    "final_data = pd.DataFrame()\n",
    "\n",
    "for variable in data['variable'].unique():\n",
    "    final_data = pd.concat([final_data,outlier_df(data[data['variable']==variable], 'value')])\n",
    "\n",
    "final_data.to_csv('{}/covariate_clinical.csv'.format(OUTPATH), index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess diagnosis covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATAPATH)\n",
    "field_list = dict(zip(diagnosis_fields_df['Code'], diagnosis_fields_df['Description']))\n",
    "\n",
    "data = df[['eid']+['{}-0.0'.format(k) for k in field_list.keys()]]\n",
    "data.index = data['eid']\n",
    "data.drop(columns='eid', inplace=True)\n",
    "data = data.unstack().reset_index().dropna().rename(columns={'level_0':'variable',0:'event_dt'})\n",
    "data['variable'] = data['variable'].str.split('-').str[0]\n",
    "data['variable'] = data['variable'].map(field_list)\n",
    "data = data[['eid','variable','event_dt']]\n",
    "data.to_csv('{}/covariate_diagnosis.csv'.format(OUTPATH), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add patients, labels and age, sex covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('{}/response.csv'.format(OUTPATH))\n",
    "df['event_dt'] = pd.to_datetime(df['event_dt'], format='%Y/%m/%d')\n",
    "\n",
    "# merge with patient covariates and add age column\n",
    "df_core = pd.read_csv('{}/patient_covariates.csv'.format(OUTPATH))\n",
    "df = pd.merge(df, df_core, on='eid', how='left')\n",
    "\n",
    "df['Age'] = df['event_dt'].dt.year - df['Year of birth']\n",
    "df.drop(columns='Year of birth', inplace=True)\n",
    "df = df[(df['Age']>18)&(df['Age']<100)]\n",
    "\n",
    "# exclude patients with number of samples less than MIN_SAMPLES\n",
    "MIN_SAMPLES = 10\n",
    "tmp = df.groupby('eid').count()\n",
    "patient_list = tmp[tmp['y']>=MIN_SAMPLES].index.tolist()\n",
    "df = df[df['eid'].isin(patient_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add treatment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add treatments reported up to T_DAYS days before event_dt\n",
    "T_DAYS = 60\n",
    "df_tre = pd.read_csv('{}/treatment.csv'.format(OUTPATH))\n",
    "df_tre = df_tre[df_tre['eid'].isin(patient_list)]\n",
    "df_tre['event_dt'] = pd.to_datetime(df_tre['event_dt'], format='%Y/%m/%d')\n",
    "df_tre['treatment'] = 'Treatment_' + df_tre['treatment']\n",
    "\n",
    "tmp = pd.merge(df[['eid','event_dt']], df_tre, on='eid', how='left').dropna()\n",
    "tmp['t'] = (tmp['event_dt_x'] - tmp['event_dt_y']).dt.days # time between event and treatment\n",
    "tmp = tmp[(tmp['t']>0)&(tmp['t']<=T_DAYS)]\n",
    "\n",
    "tmp = tmp.sort_values(by='t').drop_duplicates(subset=['eid','event_dt_x','treatment'], keep='last')\n",
    "tmp = tmp.drop(columns=['event_dt_y']).rename(columns={'event_dt_x':'event_dt'})\n",
    "tmp = pd.concat([tmp.drop(columns=['treatment','t']), pd.get_dummies(tmp['treatment'])], axis=1).groupby(['eid','event_dt']).max().reset_index()\n",
    "\n",
    "df = pd.merge(df, tmp, on=['eid','event_dt'], how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add diagnosis variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add diagnosis covariates if reported for the patient prior to event_dt\n",
    "df_diag = pd.read_csv('{}/covariate_diagnosis.csv'.format(OUTPATH))\n",
    "df_diag= df_diag[df_diag['eid'].isin(patient_list)]\n",
    "df_diag['event_dt'] = pd.to_datetime(df_diag['event_dt'], format='%Y/%m/%d')\n",
    "df_diag['variable'] = 'Diagnosis_' + df_diag['variable']\n",
    "df_diag = df_diag.sort_values(by='event_dt', ascending=False).drop_duplicates(subset=['eid','variable'], keep='first')\n",
    "tmp = pd.merge(df[['eid','event_dt']], df_diag, on='eid', how='left').dropna()\n",
    "tmp['first_diagnosis'] = (tmp['event_dt_x'] - tmp['event_dt_y']).dt.days\n",
    "tmp = tmp[tmp['first_diagnosis']>0]\n",
    "tmp['value'] = 1\n",
    "tmp = tmp.pivot_table(index=['eid','event_dt_x'],columns='variable',values='value',aggfunc=np.mean).reset_index().rename(columns={'event_dt_x':'event_dt'})\n",
    "df = pd.merge(df, tmp, on=['eid','event_dt'], how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add lab variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clinical covariates are based on most recent value in data in past T_DAYS days\n",
    "# if no values recorded then remove row from dataset\n",
    "T_DAYS = 10*12*30 # past 10 years\n",
    "df_clin = pd.read_csv('{}/covariate_clinical.csv'.format(OUTPATH))\n",
    "df_clin= df_clin[df_clin['eid'].isin(patient_list)]\n",
    "df_clin['event_dt'] = pd.to_datetime(df_clin['event_dt'], format='%Y/%m/%d')\n",
    "df_clin['variable'] = 'Clinical_' + df_clin['variable']\n",
    "\n",
    "tmp = pd.merge(df[['eid','event_dt']], df_clin, on='eid', how='left').dropna()\n",
    "tmp['time'] = (tmp['event_dt_x'] - tmp['event_dt_y']).dt.days\n",
    "tmp = tmp[(tmp['time']>0)&(tmp['time']<=T_DAYS)].sort_values(by='time').groupby(['eid','event_dt_x','variable']).first().reset_index()\n",
    "tmp = tmp.pivot_table(index=['eid','event_dt_x'],columns='variable',values='value',aggfunc=np.mean).reset_index().rename(columns={'event_dt_x':'event_dt'})\n",
    "df = pd.merge(df, tmp, on=['eid','event_dt'], how='left')\n",
    "\n",
    "# remove patients with less than MIN_SAMPLES samples\n",
    "df = df.dropna()\n",
    "tmp = df.groupby('eid').count()\n",
    "patient_list = tmp[tmp['event_dt']>=MIN_SAMPLES].index.tolist()\n",
    "df = df[df['eid'].isin(patient_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final cleanup and formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = '2010-01-01'\n",
    "# only consider patients diagnosed before cutoff date, and their data after cutoff date\n",
    "df = df[(df['T2D_diagnosis_date']<cutoff_date)&(df['event_dt']>=cutoff_date)]\n",
    "tmp = df.groupby('eid').count().reset_index()\n",
    "patient_list = tmp[tmp['event_dt']>=MIN_SAMPLES]['eid'].tolist()\n",
    "df = df[df['eid'].isin(patient_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='Diagnosis_E11 T2D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix issue where some Creatinine values are given in wrong unit\n",
    "df['Clinical_Creatinine'] = df['Clinical_Creatinine'].apply(lambda x : x/1000 if x>1000 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove patients with fluvastatin - too few samples\n",
    "eid_remove = df[df['Treatment_fluvastatin']==1]['eid'].unique().tolist()\n",
    "df = df[~df['eid'].isin(eid_remove)]\n",
    "df = df.drop(columns='Treatment_fluvastatin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clean data\n",
    "df.to_csv('data/processed/ukbb.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create random splits for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed/ukbb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/val/test datasets for experiments\n",
    "\n",
    "NUMTASKS_TRAIN = 205\n",
    "NUMTASKS_VAL = 30\n",
    "NUMTASKS_TEST = 30\n",
    "NUMSAMPLES_SPT = 5\n",
    "NUMSAMPLES_QRY = 5\n",
    "\n",
    "PATIENTS = data['eid'].unique().tolist()\n",
    "\n",
    "for dataset in range(1,4):\n",
    "\n",
    "    random.shuffle(PATIENTS)\n",
    "    train_tasks = PATIENTS[0:NUMTASKS_TRAIN]\n",
    "    val_tasks = PATIENTS[NUMTASKS_TRAIN:NUMTASKS_TRAIN+NUMTASKS_VAL]\n",
    "    test_tasks = PATIENTS[NUMTASKS_TRAIN+NUMTASKS_VAL:]\n",
    "\n",
    "    meta_train_type = {'train':0, 'val':1, 'test':2}\n",
    "    patient_list = {'train':train_tasks, 'val':val_tasks, 'test':test_tasks}\n",
    "    \n",
    "    patient_map = dict(zip(PATIENTS,range(len(PATIENTS))))\n",
    "    \n",
    "    df = data.sample(frac=1)\n",
    "    new_df = pd.DataFrame()\n",
    "    for datatype in ['train', 'val', 'test']:\n",
    "        add_data = df[df['eid'].isin(patient_list[datatype])]\n",
    "        add_data['meta_train'] = meta_train_type[datatype]\n",
    "        add_data['keep'] = (add_data.groupby('eid').cumcount() < NUMSAMPLES_SPT+NUMSAMPLES_QRY).astype(int)\n",
    "        add_data = add_data[add_data['keep']==1]\n",
    "        add_data = add_data.drop(columns='keep')\n",
    "        add_data['task_train'] = (add_data.groupby('eid').cumcount() < NUMSAMPLES_SPT).astype(int)\n",
    "        add_data['task'] = add_data['eid'].map(patient_map)\n",
    "        rename = {'y':'Y','Sex':'X_Sex','Age':'X_Age'}\n",
    "        rename.update({k:'X_{}'.format(k) for k in add_data.keys() if k.startswith('Clinical_')})\n",
    "        rename.update({k:'X_{}'.format(k) for k in add_data.keys() if k.startswith('Diagnosis_')})\n",
    "        rename.update({k:'T_{}'.format(k) for k in add_data.keys() if k.startswith('Treatment_')})\n",
    "        new_df = pd.concat([new_df, add_data.drop(columns=['eid','event_dt','T2D_diagnosis_date']).rename(columns=rename)])\n",
    "\n",
    "    new_df = new_df.sort_values(by=['task','task_train'])\n",
    "    print(new_df.info())\n",
    "    new_df.to_csv(f'data/processed/ukbb_dataset{dataset}.csv', index=None)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
