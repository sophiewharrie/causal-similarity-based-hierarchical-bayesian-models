{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mlflow runs\n",
    "experiment_id = '353509075155020587' # TODO update mlflow experiment ID if it changes (check mlruns directory)\n",
    "\n",
    "mlflow.set_tracking_uri(\"../../mlruns\")\n",
    "\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment_id])\n",
    "\n",
    "failed_runs = len(runs[runs['status']=='FAILED'][['params.model']])\n",
    "print(\"{} experiment runs failed ({}% of total)\".format(failed_runs, failed_runs/len(runs)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp for saving figures, tables and other outputs from this experiment run\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.to_csv(f'results-{timestamp}.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup the data fields for analysis\n",
    "runs['trial'] = runs['params.datafile'].str.split('_').str[-2]\n",
    "runs['value'] = runs['params.datafile'].str.split('_').str[-4].astype(float)\n",
    "runs['variable'] = runs['params.datafile'].str.split('_').str[-5]\n",
    "runs['C'] = runs['params.datafile'].str.split('_').str[-6]\n",
    "runs['params.causal_distance'] = runs['params.causal_distance'].fillna('')\n",
    "runs['params.inference_type'] = runs['params.inference_type'].fillna('')\n",
    "runs['method'] = runs['params.model'] + runs['params.causal_distance'] + runs['params.inference_type']\n",
    "\n",
    "# get best result for each trial, based on performance for validation set\n",
    "results = runs[['method','C','value','variable','trial','metrics.RMSE_avg_val','metrics.RMSE_avg_test']].sort_values(by='metrics.RMSE_avg_val').groupby(['method','C','trial','variable','value']).first().reset_index()\n",
    "results['C'] = results['C'].astype(float)\n",
    "results['metrics.RMSE_avg_test'] = results['metrics.RMSE_avg_test'].astype(float)\n",
    "\n",
    "method_names = {'global_bnn_baseline':'Global BNN baseline', \n",
    "                'individual_bnn_baseline':'Local BNNs baseline', \n",
    "                'bayesian_maml_baseline':'Meta-learning baseline',\n",
    "                'our_methodground_truth':'Ground truth reference',\n",
    "                'our_methodOD':'Our method (OD)',\n",
    "                'our_methodSHD':'Our method (SHD)',\n",
    "                'our_methodID':'Our method (ID)',\n",
    "                'our_methodSID':'Our method (SID)',\n",
    "                'our_methodobservational':'Our method (OP)',\n",
    "                'our_methodinterventional':'Our method (IP)'}\n",
    "results['method'] = results['method'].map(method_names)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot for N\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16,4))\n",
    "\n",
    "methods1 = ['Global BNN baseline', 'Local BNNs baseline', 'Meta-learning baseline', 'Our method (OD)', 'Our method (SHD)', 'Our method (ID)', 'Our method (SID)']\n",
    "methods2 = ['Global BNN baseline', 'Local BNNs baseline', 'Meta-learning baseline', 'Our method (OP)', 'Our method (IP)']\n",
    "methods3 = ['Ground truth reference', 'Our method (OD)', 'Our method (SHD)', 'Our method (ID)', 'Our method (SID)', 'Our method (OP)', 'Our method (IP)']\n",
    "\n",
    "colors = {'Global BNN baseline':'tab:blue', \n",
    "          'Local BNNs baseline':'tab:pink', \n",
    "          'Meta-learning baseline':'tab:olive', \n",
    "          'Ground truth reference':'tab:red', \n",
    "          'Our method (OD)':'tab:cyan', \n",
    "          'Our method (SHD)':'tab:brown', \n",
    "          'Our method (ID)':'tab:orange', \n",
    "          'Our method (SID)':'tab:gray', \n",
    "          'Our method (OP)':'tab:green', \n",
    "          'Our method (IP)':'tab:purple'}\n",
    "          \n",
    "colors1 = {m:colors[m] for m in methods1}\n",
    "colors2 = {m:colors[m] for m in methods2}\n",
    "colors3 = {m:colors[m] for m in methods3}\n",
    "\n",
    "ax1 = sns.lineplot(data=results[(results['method'].isin(methods1))&(results['variable']=='N')], x='value', y='metrics.RMSE_avg_test', hue='method', style='method', ax=axes[0], palette=colors1)\n",
    "ax2 = sns.lineplot(data=results[(results['method'].isin(methods2))&(results['variable']=='N')], x='value', y='metrics.RMSE_avg_test', hue='method', style='method', ax=axes[1], palette=colors2)\n",
    "ax3 = sns.lineplot(data=results[(results['method'].isin(methods3))&(results['variable']=='N')], x='value', y='metrics.RMSE_avg_test', hue='method', style='method', ax=axes[2], palette=colors3)\n",
    "\n",
    "sns.despine(left=True)\n",
    "ax1.set_ylabel('RMSE of test tasks')\n",
    "ax1.set_yscale('log')\n",
    "ax1.yaxis.set_major_locator(ticker.LogLocator(10,[0.01,0.02,0.03]))\n",
    "ax1.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "ax2.set_ylabel('RMSE of test tasks')\n",
    "ax2.set_yscale('log')\n",
    "ax2.yaxis.set_major_locator(ticker.LogLocator(10,[0.01,0.02,0.03]))\n",
    "ax2.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "ax3.set_ylabel('RMSE of test tasks')\n",
    "ax1.set_title('Baseline comparison (known CGMs)')\n",
    "ax2.set_title('Baseline comparison (unknown CGMs)')\n",
    "ax3.set_title('Causal distance and proxy comparison')\n",
    "ax1.set_xlabel('N')\n",
    "ax2.set_xlabel('N')\n",
    "ax3.set_xlabel('N')\n",
    "\n",
    "ax1.legend().set_title('')\n",
    "ax2.legend().set_title('')\n",
    "ax3.legend().set_title('')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2, borderpad=0.1, columnspacing=0.5)\n",
    "\n",
    "plt.savefig(f'results-N-{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot for m\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16,4))\n",
    "\n",
    "methods1 = ['Global BNN baseline', 'Local BNNs baseline', 'Meta-learning baseline', 'Our method (OD)', 'Our method (SHD)', 'Our method (ID)', 'Our method (SID)']\n",
    "methods2 = ['Global BNN baseline', 'Local BNNs baseline', 'Meta-learning baseline', 'Our method (OP)', 'Our method (IP)']\n",
    "methods3 = ['Ground truth reference', 'Our method (OD)', 'Our method (SHD)', 'Our method (ID)', 'Our method (SID)', 'Our method (OP)', 'Our method (IP)']\n",
    "\n",
    "colors = {'Global BNN baseline':'tab:blue', \n",
    "          'Local BNNs baseline':'tab:pink', \n",
    "          'Meta-learning baseline':'tab:olive', \n",
    "          'Ground truth reference':'tab:red', \n",
    "          'Our method (OD)':'tab:cyan', \n",
    "          'Our method (SHD)':'tab:brown', \n",
    "          'Our method (ID)':'tab:orange', \n",
    "          'Our method (SID)':'tab:gray', \n",
    "          'Our method (OP)':'tab:green', \n",
    "          'Our method (IP)':'tab:purple'}\n",
    "\n",
    "colors1 = {m:colors[m] for m in methods1}\n",
    "colors2 = {m:colors[m] for m in methods2}\n",
    "colors3 = {m:colors[m] for m in methods3}\n",
    "\n",
    "ax1 = sns.lineplot(data=results[(results['method'].isin(methods1))&(results['variable']=='M')], x='value', y='metrics.RMSE_avg_test', hue='method', style='method', ax=axes[0], palette=colors1)\n",
    "ax2 = sns.lineplot(data=results[(results['method'].isin(methods2))&(results['variable']=='M')], x='value', y='metrics.RMSE_avg_test', hue='method', style='method', ax=axes[1], palette=colors2)\n",
    "ax3 = sns.lineplot(data=results[(results['method'].isin(methods3))&(results['variable']=='M')], x='value', y='metrics.RMSE_avg_test', hue='method', style='method', ax=axes[2], palette=colors3)\n",
    "\n",
    "sns.despine(left=True)\n",
    "ax1.set_ylabel('RMSE of test tasks')\n",
    "ax1.set_yscale('log')\n",
    "ax1.yaxis.set_major_locator(ticker.LogLocator(10,[0.01,0.02,0.03]))\n",
    "ax1.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "ax2.set_ylabel('RMSE of test tasks')\n",
    "ax2.set_yscale('log')\n",
    "ax2.yaxis.set_major_locator(ticker.LogLocator(10,[0.01,0.02,0.03]))\n",
    "ax2.yaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "ax3.set_ylabel('RMSE of test tasks')\n",
    "ax1.set_title('Baseline comparison (known CGMs)')\n",
    "ax2.set_title('Baseline comparison (unknown CGMs)')\n",
    "ax3.set_title('Causal distance and proxy comparison')\n",
    "ax1.set_xlabel('M')\n",
    "ax2.set_xlabel('M')\n",
    "ax3.set_xlabel('M')\n",
    "\n",
    "\n",
    "ax1.legend().set_title('')\n",
    "ax2.legend().set_title('')\n",
    "ax3.legend().set_title('')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2, borderpad=0.1, columnspacing=0.5)\n",
    "\n",
    "plt.savefig(f'results-M-{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
