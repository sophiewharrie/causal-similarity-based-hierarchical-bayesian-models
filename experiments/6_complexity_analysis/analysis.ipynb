{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mlflow runs\n",
    "experiment_id = '779465877152455589' # TODO update mlflow experiment ID if it changes (check mlruns directory)\n",
    "\n",
    "mlflow.set_tracking_uri(\"../../mlruns\")\n",
    "\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment_id])\n",
    "\n",
    "failed_runs = len(runs[runs['status']=='FAILED'][['params.model']])\n",
    "print(\"{} experiment runs failed ({}% of total)\".format(failed_runs, failed_runs/len(runs)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp for saving figures, tables and other outputs from this experiment run\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.to_csv(f'results-{timestamp}.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup the data fields for analysis\n",
    "runs['trial'] = runs['params.datafile'].str.split('_').str[-2]\n",
    "runs['value'] = runs['params.datafile'].str.split('_').str[-4].astype(float)\n",
    "runs['variable'] = runs['params.datafile'].str.split('_').str[-5]\n",
    "runs['C'] = runs['params.datafile'].str.split('_').str[-6]\n",
    "runs['params.causal_distance'] = runs['params.causal_distance'].fillna('')\n",
    "runs['params.inference_type'] = runs['params.inference_type'].fillna('')\n",
    "runs['method'] = runs['params.model'] + runs['params.causal_distance'] + runs['params.inference_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = runs[['trial','variable','value','C','method','metrics.runtime_initialisation','metrics.runtime_main_training']]\n",
    "results = results.groupby(['variable','value','method'])['metrics.runtime_initialisation','metrics.runtime_main_training'].agg(['mean', 'std']).reset_index()\n",
    "for metric in 'metrics.runtime_initialisation','metrics.runtime_main_training':\n",
    "    results[\"{}_fmt\".format(metric)] = results.apply(lambda x: f\"{x[(metric,'mean')]:.3f} ({x[(metric,'std')]:.3f})\", axis=1)\n",
    "results['metric'] = results['metrics.runtime_initialisation_fmt'] + '\\n' + results['metrics.runtime_main_training_fmt']\n",
    "results = results[['variable','value','method','metric']]\n",
    "results = results.pivot(index=['variable','value'],columns='method',values='metric').reset_index()\n",
    "results.to_csv(f'results-timing-{timestamp}.csv', index=None)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
